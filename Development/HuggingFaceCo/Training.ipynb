{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carson\\onedrive\\desktop\\programming\\projects\\epic\\transformers\\src\\transformers\\modeling_auto.py:810: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Path:\t C:\\Users\\Carson\\OneDrive\\Desktop\\Programming\\Projects\\Epic\\Data\\Outputs\\Stephen_King_Playground\\merged_Stephen_King_train.txt\n",
      "Test Path:\t C:\\Users\\Carson\\OneDrive\\Desktop\\Programming\\Projects\\Epic\\Data\\Outputs\\Stephen_King_Playground\\merged_Stephen_King_test.txt\n",
      "Output Directory Path:\t C:\\Users\\Carson\\OneDrive\\Desktop\\Programming\\Projects\\Epic\\Data\\Outputs\\Stephen_King_Playground\\gpt2_small_outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carson\\onedrive\\desktop\\programming\\projects\\epic\\transformers\\src\\transformers\\trainer.py:246: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead. Setting `args.prediction_loss_only=True\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython import display\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config()\n",
    "# Initializing a model from the configuration\n",
    "model = GPT2Model(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "# print(configuration)\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "# Download model and configuration from S3 and cache.\n",
    "model = AutoModelWithLMHead.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n",
    "train_path = os.path.abspath(os.path.join(\"../\", os.pardir))+ '\\Data\\Outputs\\Stephen_King_Playground\\merged_Stephen_King_train.txt';\n",
    "test_path = os.path.abspath(os.path.join(\"../\", os.pardir))+ '\\Data\\Outputs\\Stephen_King_Playground\\merged_Stephen_King_test.txt';\n",
    "output_path = os.path.abspath(os.path.join(\"../\", os.pardir))+ '\\Data\\Outputs\\Stephen_King_Playground\\gpt2_small_outputs'\n",
    "print(\"Train Path:\\t\", train_path)\n",
    "print(\"Test Path:\\t\", test_path)\n",
    "print(\"Output Directory Path:\\t\", output_path)\n",
    "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_path, #The output directory\n",
    "    overwrite_output_dir=False, #overwrite the content of the output directory\n",
    "    num_train_epochs=5, # number of training epochs\n",
    "    per_device_train_batch_size=7, # batch size for training\n",
    "    per_device_eval_batch_size=7,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=1000, # after # steps model is saved\n",
    "    warmup_steps=1000,# number of warmup steps for learning rate scheduler\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ec2da375c34487bf41e44a5580b017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22960.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.815122314453125, 'learning_rate': 2.5e-05, 'epoch': 0.10888501742160278}\n",
      "{'loss': 3.664017822265625, 'learning_rate': 5e-05, 'epoch': 0.21777003484320556}\n",
      "{'loss': 3.58491064453125, 'learning_rate': 4.8861566484517307e-05, 'epoch': 0.32665505226480834}\n",
      "{'loss': 3.5343935546875, 'learning_rate': 4.772313296903461e-05, 'epoch': 0.4355400696864111}\n",
      "{'loss': 3.4940791015625, 'learning_rate': 4.6584699453551915e-05, 'epoch': 0.544425087108014}\n",
      "{'loss': 3.445609375, 'learning_rate': 4.544626593806922e-05, 'epoch': 0.6533101045296167}\n",
      "{'loss': 3.40947265625, 'learning_rate': 4.430783242258652e-05, 'epoch': 0.7621951219512195}\n",
      "{'loss': 3.39899609375, 'learning_rate': 4.316939890710383e-05, 'epoch': 0.8710801393728222}\n",
      "{'loss': 3.368326171875, 'learning_rate': 4.203096539162113e-05, 'epoch': 0.9799651567944251}\n",
      "{'loss': 3.251853515625, 'learning_rate': 4.0892531876138436e-05, 'epoch': 1.088850174216028}\n",
      "{'loss': 3.2192109375, 'learning_rate': 3.975409836065574e-05, 'epoch': 1.1977351916376306}\n",
      "{'loss': 3.20261328125, 'learning_rate': 3.8615664845173044e-05, 'epoch': 1.3066202090592334}\n",
      "{'loss': 3.18898828125, 'learning_rate': 3.747723132969035e-05, 'epoch': 1.4155052264808363}\n",
      "{'loss': 3.1825859375, 'learning_rate': 3.633879781420765e-05, 'epoch': 1.524390243902439}\n",
      "{'loss': 3.1639140625, 'learning_rate': 3.520036429872496e-05, 'epoch': 1.6332752613240418}\n",
      "{'loss': 3.15376953125, 'learning_rate': 3.406193078324226e-05, 'epoch': 1.7421602787456445}\n",
      "{'loss': 3.15262890625, 'learning_rate': 3.2923497267759565e-05, 'epoch': 1.8510452961672472}\n",
      "{'loss': 3.13420703125, 'learning_rate': 3.178506375227687e-05, 'epoch': 1.9599303135888502}\n",
      "{'loss': 3.06307421875, 'learning_rate': 3.0646630236794174e-05, 'epoch': 2.068815331010453}\n",
      "{'loss': 3.001, 'learning_rate': 2.9508196721311478e-05, 'epoch': 2.177700348432056}\n",
      "{'loss': 3.0180234375, 'learning_rate': 2.8369763205828782e-05, 'epoch': 2.2865853658536586}\n",
      "{'loss': 2.99709375, 'learning_rate': 2.7231329690346086e-05, 'epoch': 2.3954703832752613}\n",
      "{'loss': 3.006671875, 'learning_rate': 2.609289617486339e-05, 'epoch': 2.504355400696864}\n",
      "{'loss': 2.98465625, 'learning_rate': 2.495446265938069e-05, 'epoch': 2.6132404181184667}\n",
      "{'loss': 2.99203125, 'learning_rate': 2.3816029143898e-05, 'epoch': 2.72212543554007}\n",
      "{'loss': 2.9801484375, 'learning_rate': 2.2677595628415303e-05, 'epoch': 2.8310104529616726}\n",
      "{'loss': 2.9799296875, 'learning_rate': 2.1539162112932607e-05, 'epoch': 2.9398954703832754}\n",
      "{'loss': 2.9252265625, 'learning_rate': 2.040072859744991e-05, 'epoch': 3.048780487804878}\n",
      "{'loss': 2.8938046875, 'learning_rate': 1.9262295081967212e-05, 'epoch': 3.157665505226481}\n",
      "{'loss': 2.8856015625, 'learning_rate': 1.8123861566484516e-05, 'epoch': 3.2665505226480835}\n",
      "{'loss': 2.8746328125, 'learning_rate': 1.6985428051001824e-05, 'epoch': 3.3754355400696863}\n",
      "{'loss': 2.8559375, 'learning_rate': 1.5846994535519128e-05, 'epoch': 3.484320557491289}\n",
      "{'loss': 2.8656640625, 'learning_rate': 1.4708561020036429e-05, 'epoch': 3.5932055749128917}\n",
      "{'loss': 2.869640625, 'learning_rate': 1.3570127504553735e-05, 'epoch': 3.702090592334495}\n",
      "{'loss': 2.8634609375, 'learning_rate': 1.2431693989071039e-05, 'epoch': 3.8109756097560976}\n",
      "{'loss': 2.8611328125, 'learning_rate': 1.1293260473588343e-05, 'epoch': 3.9198606271777003}\n",
      "{'loss': 2.8397421875, 'learning_rate': 1.0154826958105647e-05, 'epoch': 4.0287456445993035}\n",
      "{'loss': 2.7961796875, 'learning_rate': 9.016393442622952e-06, 'epoch': 4.137630662020906}\n",
      "{'loss': 2.8002109375, 'learning_rate': 7.877959927140254e-06, 'epoch': 4.246515679442509}\n",
      "{'loss': 2.8004375, 'learning_rate': 6.73952641165756e-06, 'epoch': 4.355400696864112}\n",
      "{'loss': 2.801359375, 'learning_rate': 5.601092896174863e-06, 'epoch': 4.464285714285714}\n",
      "{'loss': 2.8004375, 'learning_rate': 4.4626593806921675e-06, 'epoch': 4.573170731707317}\n",
      "{'loss': 2.791453125, 'learning_rate': 3.3242258652094717e-06, 'epoch': 4.68205574912892}\n",
      "{'loss': 2.7911875, 'learning_rate': 2.185792349726776e-06, 'epoch': 4.790940766550523}\n",
      "{'loss': 2.788640625, 'learning_rate': 1.0473588342440803e-06, 'epoch': 4.899825783972125}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22960, training_loss=3.071871257077526)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to parse C:\\Users\\Carson\\OneDrive\\Desktop\\Programming\\Projects\\Epic\\Data\\Outputs\\Stephen_King_Playground\\gpt2_small_outputs\\modelcard.json as a URL or as a local path",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4f965d8a6cdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text-generation'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'max_length'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input Prompt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'generated_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carson\\onedrive\\desktop\\programming\\projects\\epic\\transformers\\src\\transformers\\pipelines.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, framework, **kwargs)\u001b[0m\n\u001b[0;32m   2722\u001b[0m     \u001b[1;31m# Instantiate modelcard if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelcard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2724\u001b[1;33m         \u001b[0mmodelcard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelcard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m     \u001b[1;31m# Instantiate model if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carson\\onedrive\\desktop\\programming\\projects\\epic\\transformers\\src\\transformers\\modelcard.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# Load from URL or cache if already cached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mresolved_model_card_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_card_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresolved_model_card_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carson\\onedrive\\desktop\\programming\\projects\\epic\\transformers\\src\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[0;32m    846\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \u001b[1;31m# Something unknown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unable to parse {} as a URL or as a local path\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mextract_compressed_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unable to parse C:\\Users\\Carson\\OneDrive\\Desktop\\Programming\\Projects\\Epic\\Data\\Outputs\\Stephen_King_Playground\\gpt2_small_outputs\\modelcard.json as a URL or as a local path"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation',model=output_path, tokenizer=tokenizer ,config={'max_length':800})\n",
    "\n",
    "result = generator('Input Prompt')[0]['generated_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
